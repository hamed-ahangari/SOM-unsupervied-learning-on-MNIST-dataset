{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1_linear_sampled_weights.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4JRsztsiFTD"
      },
      "source": [
        "# **SOM** - Linear map & Sampled initialization of weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO200LCriPEJ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NP7rIqGtE9m"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "from math import exp\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNfVK_eNirta"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVIhAnVRiuK5",
        "outputId": "1991e795-fda4-44f4-d725-1c46d592510a"
      },
      "source": [
        "iterations = 20\n",
        "\n",
        "(_, _), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "reduced_mnist_images = [test_images[np.random.choice(a=np.where(test_labels == j)[0], size=100)] for j in range(10)]\n",
        "reduced_mnist_images = np.array(reduced_mnist_images, dtype='float32') / 255\n",
        "\n",
        "reduced_mnist_images = reduced_mnist_images.reshape((1000, 784))\n",
        "reduced_mnist_labels = np.array([100*[i] for i in range(10)], dtype='int').ravel()\n",
        "\n",
        "shuffled_indices = np.random.permutation(np.arange(1000))\n",
        "\n",
        "reduced_mnist_images = reduced_mnist_images[shuffled_indices]\n",
        "reduced_mnist_labels = reduced_mnist_labels[shuffled_indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpI4AtmljCNs"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP0O_Yf-XiFA"
      },
      "source": [
        "def learning_rate_generator_with_decay():\n",
        "   global iterations\n",
        "   time = 0\n",
        "   while True:\n",
        "       yield (1 - (time/iterations))\n",
        "       time += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kZRK7RnZGT3"
      },
      "source": [
        "# Define the weight matrix\n",
        "# and fill it with random samples from reduced MNIST set (625 random of 1000 samples)\n",
        "# the dimensions are 784 (input size) by 625 (neurons/clusters)\n",
        "som_weight_matrix = reduced_mnist_images[np.random.choice(np.arange(1000), size=625, replace=False)].transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj2zV8xc6XEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c3e992-5803-4d84-ba7c-590a73596ba7"
      },
      "source": [
        "lr_with_decay = learning_rate_generator_with_decay()    # instantiate a lr generator\n",
        "\n",
        "weights_snapshot = {0 : som_weight_matrix.copy()}   # snapshot for some epochs\n",
        "coverage_history = np.zeros((iterations+1, 625), dtype=bool)\n",
        "\n",
        "winning_counts = dict()\n",
        "winning_classes_counts = dict()\n",
        "\n",
        "for epoch in range(iterations):\n",
        "\n",
        "    lr = next(lr_with_decay)    # Get new learning rate value\n",
        "\n",
        "    start = time.time()     # start the timer\n",
        "\n",
        "    for x in range(1000):    \n",
        "\n",
        "        # Calculate Euclidean distance for all neurons\n",
        "        distance_matrix = np.sqrt(((som_weight_matrix.transpose() - reduced_mnist_images[x])**2).sum(axis = 1))\n",
        "\n",
        "        # Find index of minimum distance\n",
        "        winner_unit = np.argmin(distance_matrix)\n",
        "        coverage_history[epoch, winner_unit] = True\n",
        "\n",
        "        # Update the neuron's weights\n",
        "        dif = reduced_mnist_images[x] - som_weight_matrix[:, winner_unit]\n",
        "        som_weight_matrix[:, winner_unit] += (dif * lr)\n",
        "        \n",
        "        # If it is the last epoch, we want to store the winning statistics of neurons\n",
        "        if epoch + 1 == iterations:\n",
        "            winning_counts[winner_unit] = winning_counts.get(winner_unit, 0) + 1\n",
        "            winning_classes_counts[(winner_unit, reduced_mnist_labels[x])] = winning_classes_counts.get((winner_unit, reduced_mnist_labels[x]), 0) + 1\n",
        "    \n",
        "    end = time.time()\n",
        "    print(\"epoch %d - %.3f s\" % (epoch + 1, end - start))\n",
        "\n",
        "    weights_snapshot[epoch + 1] = som_weight_matrix.copy()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 - 1.047 s\n",
            "epoch 2 - 0.859 s\n",
            "epoch 3 - 0.868 s\n",
            "epoch 4 - 0.874 s\n",
            "epoch 5 - 0.887 s\n",
            "epoch 6 - 0.894 s\n",
            "epoch 7 - 0.904 s\n",
            "epoch 8 - 0.920 s\n",
            "epoch 9 - 0.935 s\n",
            "epoch 10 - 0.955 s\n",
            "epoch 11 - 0.949 s\n",
            "epoch 12 - 0.962 s\n",
            "epoch 13 - 0.979 s\n",
            "epoch 14 - 1.002 s\n",
            "epoch 15 - 1.001 s\n",
            "epoch 16 - 0.999 s\n",
            "epoch 17 - 1.020 s\n",
            "epoch 18 - 0.900 s\n",
            "epoch 19 - 0.883 s\n",
            "epoch 20 - 1.031 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t55YAXPOsp6S"
      },
      "source": [
        "### Show twenty neurons with the most winnings at the last epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdoqfnyNE2GH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "2b849496-8bf7-4b21-8b54-1df737653a03"
      },
      "source": [
        "twenty_neurons_with_most_winning = [k for k, v in sorted(winning_counts.items(), key=lambda item: item[1], reverse = True)][:20]\n",
        "\n",
        "stat_table = np.zeros((20,10), dtype='int')\n",
        "\n",
        "for i, neu in enumerate(twenty_neurons_with_most_winning):\n",
        "    for class_label in range(0, 10):\n",
        "        stat_table[i][class_label] = winning_classes_counts.get((neu, class_label), 0)\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "df = pd.DataFrame(stat_table, index=twenty_neurons_with_most_winning, columns=['label {0}'.format(i) for i in range(0,10)])\n",
        "df['Total'] = df.sum(axis=1)\n",
        "print(\"Total sum:  %d images\" % df['Total'].sum())\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sum:  106 images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label 0</th>\n",
              "      <th>label 1</th>\n",
              "      <th>label 2</th>\n",
              "      <th>label 3</th>\n",
              "      <th>label 4</th>\n",
              "      <th>label 5</th>\n",
              "      <th>label 6</th>\n",
              "      <th>label 7</th>\n",
              "      <th>label 8</th>\n",
              "      <th>label 9</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label 0  label 1  label 2  label 3  ...  label 7  label 8  label 9  Total\n",
              "516        0        0        0        0  ...        0        0       10     10\n",
              "271        0        0        0        0  ...        0        0        0      7\n",
              "597        0        0        0        0  ...        0        0        6      6\n",
              "207        0        6        0        0  ...        0        0        0      6\n",
              "552        0        0        0        0  ...        0        0        6      6\n",
              "123        0        0        0        0  ...        0        6        0      6\n",
              "614        0        5        0        0  ...        0        0        0      5\n",
              "527        0        0        0        5  ...        0        0        0      5\n",
              "188        0        0        0        0  ...        0        0        0      5\n",
              "235        0        0        0        0  ...        0        0        4      5\n",
              "371        0        0        0        0  ...        0        0        0      5\n",
              "346        0        0        0        5  ...        0        0        0      5\n",
              "172        0        0        0        0  ...        0        0        5      5\n",
              "498        0        0        0        0  ...        0        0        5      5\n",
              "608        0        0        0        0  ...        0        0        0      5\n",
              "492        0        4        0        0  ...        0        0        0      4\n",
              "315        0        0        0        0  ...        0        0        0      4\n",
              "354        0        0        0        4  ...        0        0        0      4\n",
              "475        0        0        0        0  ...        4        0        0      4\n",
              "311        4        0        0        0  ...        0        0        0      4\n",
              "\n",
              "[20 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9af9ouESjm1b"
      },
      "source": [
        "### Generate and save figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtXqIiOc-dgI"
      },
      "source": [
        "import os\n",
        "os.makedirs('./linear-topology_sampled-weights/', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4pFATVPFOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6d8722-cbde-4ac5-8b98-92649ea056ca"
      },
      "source": [
        "for epoch, weight_mat in weights_snapshot.items():\n",
        "    fig = plt.figure(figsize=(17,17))\n",
        "    axes = [fig.add_subplot(25,25,i+1) for i in range(625)]\n",
        "\n",
        "    for n, ax in enumerate(axes):\n",
        "        ax.imshow(weight_mat[:,n].reshape((28,28)), cmap=(\"gray_r\" if coverage_history[epoch, n] == False else \"plasma\"))\n",
        "\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        if n >= 600: ax.set_xlabel(n%25 + 1)\n",
        "        if n%25==0: ax.set_ylabel(n//25 + 1)\n",
        "        ax.tick_params(axis='both', which='both', length=0)\n",
        "        ax.label_outer\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "    fig.suptitle(\"Epoch %d - [Linear Topology , Sampled Weights Initialization]\" % epoch, fontsize=18)\n",
        "\n",
        "    # write the figure for this epoch on disk\n",
        "    path = f\"./linear-topology_sampled-weights/epoch-{epoch}\"\n",
        "    fig.savefig(path)\n",
        "    plt.close(fig)\n",
        "\n",
        "    print(f\"Saved: {path}.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: ./linear-topology_sampled-weights/epoch-0.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-1.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-2.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-3.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-4.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-5.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-6.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-7.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-8.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-9.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-10.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-11.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-12.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-13.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-14.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-15.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-16.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-17.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-18.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-19.png\n",
            "Saved: ./linear-topology_sampled-weights/epoch-20.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URmK6GxcnEjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8672f9-59b2-4799-f8ea-de496923e3bb"
      },
      "source": [
        "!zip -r linear_sampled.zip /content/linear-topology_sampled-weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/linear-topology_sampled-weights/ (stored 0%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-20.png (deflated 11%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-14.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-13.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-3.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-5.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-4.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-10.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-6.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-2.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-0.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-18.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-11.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-1.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-7.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-12.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-9.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-8.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-15.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-19.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-17.png (deflated 1%)\n",
            "  adding: content/linear-topology_sampled-weights/epoch-16.png (deflated 1%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}